{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "582671c5-1f3f-4511-9696-8c0e0ffc5251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting schedule\n",
      "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: schedule\n",
      "Successfully installed schedule-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a469e2e9-04a1-490d-997d-87e6127c2445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from seaborn) (2.1.4)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from seaborn) (3.7.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jepar\\anaconda3\\envs\\ocean\\lib\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d96f9c-561a-4b14-a127-9527ed2fa86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import joblib\n",
    "import schedule\n",
    "import pandas as pd\n",
    "import time as st_time\n",
    "from datetime import datetime, date, timedelta, time\n",
    "os.environ['TZ'] ='America/New_York'\n",
    "\n",
    "#import yfinance as yf\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from ib_async import *\n",
    "util.startLoop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f8d42-045b-4c3b-bb98-0d5acdb61696",
   "metadata": {},
   "source": [
    "### Data Prep for Inferencing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d4390b-5d51-473d-8b43-99cfd36e358a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ib = IB()\n",
    "ib.connect(port=7496, clientId=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b449be-0864-467d-b67a-dfae1d5024e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = Contract(symbol='MSFT', secType='STK', exchange='SMART', currency='USD')\n",
    "ib.qualifyContracts(contract)\n",
    "\n",
    "contract_vix = Contract(symbol= 'VIX', secType = 'IND',exchange = 'CBOE', currency='USD')\n",
    "ib.qualifyContracts(contract_vix)\n",
    "\n",
    "contract_nas = Contract(symbol= 'TQQQ', secType = 'STK',exchange = 'SMART', currency='USD')\n",
    "ib.qualifyContracts(contract_nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3c69b4-8edf-4908-a798-35f519661718",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_Request :\n",
    "\n",
    "    \"\"\"\n",
    "    Returns PD data containning equity price with specific time control\n",
    "\n",
    "    Returns:\n",
    "        pd: information regarding the contract of interst.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, list_days, contract, barsize, duration, *,specific_time= None, specific_pick_time= None):\n",
    "\n",
    "        self.list_days = list_days\n",
    "        self.contract = contract\n",
    "        #self.init_date = init_date\n",
    "        self.barsize = barsize\n",
    "        self.duration = duration\n",
    "        self.specific_time = specific_time # cut off time . Time object: time(14, 30, 0)\n",
    "        self.specific_pick_time= specific_pick_time\n",
    "\n",
    "    def D_request(self):\n",
    "\n",
    "        his_df =pd.DataFrame()\n",
    "        \n",
    "        for i in range(len(self.list_days)):\n",
    "            init_date=self.list_days[i]\n",
    "            bars = ib.reqHistoricalData(self.contract, init_date, barSizeSetting=self.barsize, durationStr=self.duration, whatToShow=\"TRADES\", useRTH=True)\n",
    "            add_his_df = pd.DataFrame(bars)\n",
    "            add_his_df['date'] = pd.to_datetime(add_his_df['date'])\n",
    "            print(f'retriveing data for {init_date}')\n",
    "\n",
    "            if self.specific_time is not None:\n",
    "                cut_off = datetime.combine(self.list_days[i],self.specific_time)  # need logic if specific_time is defined\n",
    "                pd_cut_off = pd.to_datetime(cut_off).tz_localize('US/Eastern')\n",
    "            #datetime64_eastern = pd.Timestamp(date_time_str).tz_localize('US/Eastern')\n",
    "                add_his_df = add_his_df[add_his_df['date'] > pd_cut_off]\n",
    "            \n",
    "            if self.specific_pick_time is not None:\n",
    "                pick_time = datetime.combine(self.list_days[i],self.specific_pick_time)  # need logic if specific_time is defined\n",
    "                pd_pick_time = pd.to_datetime(pick_time).tz_localize('US/Eastern')\n",
    "            #datetime64_eastern = pd.Timestamp(date_time_str).tz_localize('US/Eastern')\n",
    "                add_his_df = add_his_df[add_his_df['date'] == pd_pick_time]\n",
    "\n",
    "            \n",
    "            his_df = pd.concat([his_df, add_his_df], ignore_index=True)\n",
    "            his_df['Date_Only'] = his_df['date'].dt.date\n",
    "            print(len(his_df))\n",
    "\n",
    "        \n",
    "        return his_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbbea47-4a8d-47f3-b363-b159f14514b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# picking out Friday and before specific-time data\n",
    "\n",
    "#specific_time = time(14, 30, 0)\n",
    "def data_filter_v46(df_initial, list_days, specific_time_before = None, specific_time_after= None, on_time= None):\n",
    "    his_df = pd.DataFrame()\n",
    "\n",
    "    df_trimmed = df_initial[df_initial['date'].dt.date.isin(list_days)]\n",
    "\n",
    "    if specific_time_before is not None:\n",
    "\n",
    "        his_df = df_trimmed[(df_trimmed['date'].dt.time < specific_time_before)]\n",
    "        \n",
    "            \n",
    "    if specific_time_after is not None:\n",
    "\n",
    "        his_df = df_trimmed[(df_trimmed['date'].dt.time >= specific_time_after)]\n",
    "\n",
    "    if on_time is not None:\n",
    "        his_df = df_trimmed[(df_trimmed['date'].dt.time == on_time)]\n",
    "\n",
    "    if (specific_time_before is None and specific_time_after is None) and on_time is None:\n",
    "\n",
    "        his_df = df_trimmed\n",
    "        \n",
    "    return his_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4f3117-47fe-4a14-be16-0dc0ef7eaa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df, in_days):\n",
    "    df_his = pd.DataFrame()\n",
    "    df_return = pd.DataFrame()\n",
    "    \n",
    "    df.drop_duplicates(inplace = True)\n",
    "    df_his = df[df[\"Date_Only\"].isin(in_days)]\n",
    "    df_return = df_his[(df_his['date'].dt.time > time(9,29,40)) & (df_his['date'].dt.time < time(16,00))]\n",
    "\n",
    "    for i in df_return['Date_Only'].unique():\n",
    "        if df_return[df_return['Date_Only'] ==i].shape[0] % 390 != 0:\n",
    "            print(i)\n",
    "    \n",
    "    return df_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b748e96-b721-4e16-8b86-e0b93f064253",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_sparcing_construc(df, sp_day, *, cut_time = None):\n",
    "    #df_group = df.groupby(\"Date_Only\").std(numeric_only=True)\n",
    "    df_filter_prior = data_filter_v46(df, sp_day, specific_time_before = cut_time )\n",
    "    df_group_prior = df_filter_prior.groupby(\"Date_Only\").std(numeric_only=True)\n",
    "    \n",
    "    #df_filter_after = data_filter(df, sp_day, specific_time_after = cut_time )\n",
    "    #df_group_after = df_filter_after.groupby(\"Date_Only\").std(numeric_only=True)\n",
    "\n",
    "\n",
    "    df_group_train =pd.DataFrame()\n",
    "    #df_group_train['Target_std'] = pd.DataFrame(df_group_after[['open','high','low','close']].max(axis=1))\n",
    "    df_group_train['prior_std'] = pd.DataFrame(df_group_prior[['open','high','low','close']].max(axis=1))\n",
    "    df_group_train['prior_Vol'] = pd.DataFrame(df_filter_prior.groupby(\"Date_Only\").mean()['volume'])\n",
    "    df_group_train['prior_spread'] = df_filter_prior.groupby('Date_Only')['open'].max() - df_filter_prior.groupby('Date_Only')['open'].min()\n",
    "\n",
    "\n",
    "    df_group_train['prior_range'] =pd.DataFrame(df_filter_prior.groupby('Date_Only')['close'].max() -df_filter_prior.groupby('Date_Only')['close'].min() )\n",
    "\n",
    "    df_initial = df_filter_prior\n",
    "    new_time = time(cut_time.hour, cut_time.minute -1)\n",
    "    df_group_train['cut_open'] = df_initial[(df_initial['date'].dt.time == new_time)]['open'].values\n",
    "    \n",
    "    cut_name =['cut_1hr','cut_2hr','cut_3hr']\n",
    "    for i in range(3):\n",
    "        print(f'time avaiable {i}')\n",
    "        prior = time(cut_time.hour - (i+1), cut_time.minute)\n",
    "        df_group_train[cut_name[i]] = df_initial[(df_initial['date'].dt.time == new_time)]['open'].values- df_initial[(df_initial['date'].dt.time == prior)]['open'].values\n",
    "\n",
    "    #df_group_train['Class_target'] = df_filter_after[(df_filter_after['date'].dt.time == time(15, 49, 0))]['close'].values- df_initial[(df_initial['date'].dt.time == new_time)]['open'].values\n",
    "    \n",
    "    return df_group_train, df_filter_prior, df_group_prior\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee95fd-7d80-4694-bad6-ff57e4095246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_option_chain(symbol):\n",
    "    contract = Stock(symbol=symbol, exchange='SMART', currency='USD')\n",
    "    ib.qualifyContracts(contract)\n",
    "    chains = ib.reqSecDefOptParams(underlyingSymbol=contract.symbol, futFopExchange=\"\", underlyingSecType=contract.secType, underlyingConId=contract.conId)\n",
    "    chain = [ c for c in chains if c.exchange =='SMART'][0]\n",
    "    return chain\n",
    "\n",
    "def get_options_chain_for_expiry(symbol, expiry, min_strike=0, max_strike=np.Inf):\n",
    "    option_chain = get_option_chain(symbol)\n",
    "    options=[]\n",
    "    for strike in option_chain.strikes:\n",
    "        if strike <= max_strike and strike >= min_strike:\n",
    "            for right in ['C', 'P']:\n",
    "                option = Option(symbol=symbol, lastTradeDateOrContractMonth=expiry, strike=strike, right=right, exchange='SMART', currency='USD')\n",
    "                options.append(option)\n",
    "    valid_options=ib.qualifyContracts(*options)\n",
    "    return valid_options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4008ca-008b-4373-9092-ad3959948bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_up_to_nearest_ten(num):\n",
    "  \"\"\"Rounds a number up to the nearest ten.\"\"\"\n",
    "  return math.ceil(num / 10) * 10\n",
    "\n",
    "\n",
    "def find_closest_number(numbers, target):\n",
    "  \"\"\"\n",
    "  Finds the number in a list that is closest to a target number.\n",
    "\n",
    "  Args:\n",
    "    numbers: A list of numbers.\n",
    "    target: The target number.\n",
    "\n",
    "  Returns:\n",
    "    The number in the list that is closest to the target number.\n",
    "  \"\"\"\n",
    "  if not numbers:\n",
    "    return None\n",
    "  \n",
    "  closest_number = numbers[0]\n",
    "  min_difference = abs(numbers[0] - target)\n",
    "\n",
    "  for number in numbers:\n",
    "    difference = abs(number - target)\n",
    "    if difference < min_difference:\n",
    "      min_difference = difference\n",
    "      closest_number = number\n",
    "\n",
    "  return closest_number\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c8eb67-543d-4ad9-b613-d44a8b3f966c",
   "metadata": {},
   "source": [
    "### Inferencing Data Set Collection ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17c1bfd-15ee-42ed-8456-0afd00ae3877",
   "metadata": {},
   "outputs": [],
   "source": [
    "now =datetime.now()\n",
    "#print(now.date())\n",
    "#print(now.time().minute)\n",
    "#infer_time = time(now.time().hour, now.time().minute -15 )\n",
    "#infer_time = time(now.time().hour, now.time().minute)\n",
    "#inferencing_date = now.date() - timedelta(3)\n",
    "inferencing_date = now.date() \n",
    "#infer_time = time(14,30,0)\n",
    "infer_time = time(now.time().hour, now.time().minute)\n",
    "## put option expiration date in 20250411 format\n",
    "to_day = \"20250411\"\n",
    "print(to_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589e327-82a1-4149-a84a-c675c6ee85c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "barsize =\"30 secs\"\n",
    "duration = \"1 D\"\n",
    "#DR_stock_MSFT = Data_Request( \" \",contract, barsize, duration)\n",
    "DR_stock_MSFT = Data_Request([inferencing_date], contract, barsize, duration)\n",
    "df_all_days_stock = DR_stock_MSFT.D_request()\n",
    "\n",
    "DR_IND_VIX = Data_Request([inferencing_date], contract_vix, barsize, duration)\n",
    "DR_STK_TQQQ = Data_Request([inferencing_date], contract_nas, barsize, duration)\n",
    "df_all_days_VIX = DR_IND_VIX.D_request()\n",
    "df_all_days_TQQQ = DR_STK_TQQQ.D_request()\n",
    "\n",
    "df_stock = data_cleaning(df_all_days_stock,[inferencing_date])\n",
    "df_VIX = data_cleaning(df_all_days_VIX,[inferencing_date])\n",
    "df_TQQQ = data_cleaning(df_all_days_TQQQ,[inferencing_date])\n",
    "\n",
    "\n",
    "df_group_train, df_filter_prior, df_group_prior = data_sparcing_construc(df_all_days_stock, [inferencing_date], cut_time= infer_time)\n",
    "df_group_train_tqqq, *_ = data_sparcing_construc(df_all_days_TQQQ, [inferencing_date], cut_time= infer_time)\n",
    "\n",
    "# need to check\n",
    "vix_infer_time = time(now.time().hour -1, now.time().minute )\n",
    "#vix_infer_time = infer_time \n",
    "df_group_train_vix, *_ = data_sparcing_construc(df_all_days_VIX, [inferencing_date], cut_time= vix_infer_time)\n",
    "\n",
    "df_final_joninted_vix=pd.DataFrame()\n",
    "df_final_joninted_all=pd.DataFrame()\n",
    "\n",
    "df_group_train_vix.columns =['vix_prior_std','vix_Vol','vix_pr_spread','vix_prior_range','vix_cut_open','vix_cut_1hr','vix_cut_2hr','vix_cut_3hr']\n",
    "df_final_jointed_vix = pd.concat([df_group_train,df_group_train_vix], axis=1)\n",
    "df_group_train_tqqq.columns =['tqqq_prior_std','tqqq_Vol','tqqq_pr_spread','tqqq_prior_range','tqqq_cut_open','tqqq_cut_1hr','tqqq_cut_2hr','tqqq_cut_3hr']\n",
    "df_final_jointed_all = pd.concat([df_final_jointed_vix,df_group_train_tqqq], axis=1)\n",
    "df_final_jointed_all.drop(['vix_Vol'], axis=1, inplace=True)\n",
    "\n",
    "df_final_jointed_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b78643a-6f7d-43da-ac83-561e67730dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_days_VIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed14798-e098-4e98-a878-c475ce71f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### use model to predict block\n",
    "\n",
    "df_final_jointed_all.reset_index(inplace=True)\n",
    "inference_data = df_final_jointed_all.drop('Date_Only', axis=1)\n",
    "inference_data.shape\n",
    "\n",
    "filename = 'xgb_model4_price_spread.joblib'\n",
    "loaded_model = joblib.load(filename)\n",
    "\n",
    "yhat = loaded_model.predict(inference_data)\n",
    "print(f'yhat {yhat}')\n",
    "\n",
    "Entry = df_all_days_stock.tail(1)['close'].values\n",
    "\n",
    "y_value = Entry\n",
    "y_value_p = Entry + yhat[0]\n",
    "y_value_m = Entry - yhat[0]\n",
    "\n",
    "print(y_value_p, Entry ,y_value_m )\n",
    "\n",
    "df_all_days_stock['close'].plot()\n",
    "plt.xlabel('time')\n",
    "plt.axhline(y=y_value, color='r', linestyle='--', label=f'y = {y_value}')\n",
    "plt.axhline(y=y_value_p, color='black', linestyle='--', label=f'y = {y_value_p}')\n",
    "plt.axhline(y=y_value_m, color='black', linestyle='--', label=f'y = {y_value_m}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f3c1e8-e559-4175-9031-f328594c2102",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  GETTTING OPTION information\n",
    "Rd_up_Entry = round_up_to_nearest_ten(Entry[0])\n",
    "\n",
    "# getting valid option chains\n",
    "\n",
    "valid_options = get_options_chain_for_expiry(\"MSFT\", to_day , min_strike= Rd_up_Entry  -30, max_strike=Rd_up_Entry +30,)\n",
    "#print(valid_options)\n",
    "\n",
    "list_strke = []\n",
    "for list_str in valid_options:\n",
    "    list_strke.append(list_str.strike)\n",
    "    \n",
    "### OPTION to find closes available strike price\n",
    "\n",
    "upper_strk_number = find_closest_number(list_strke, y_value_p[0])\n",
    "\n",
    "#global Up_Call\n",
    "Up_Call = upper_strk_number +5\n",
    "\n",
    "lower_strk_number = find_closest_number(list_strke, y_value_m[0])\n",
    "\n",
    "#global Down_Put\n",
    "Down_Put = lower_strk_number - 5 \n",
    "\n",
    "tickers_dict = {}\n",
    "    \n",
    "for option in valid_options:\n",
    "    tickers_dict[(option.right, option.strike)] = ib.reqMktData(contract =option, genericTickList=\"\", snapshot=False, regulatorySnapshot=False)\n",
    "\n",
    "## call empty call to wait\n",
    "ib.sleep(4)\n",
    "###\n",
    "###\n",
    "ticker_call_to_sell_target = tickers_dict['C', Up_Call]\n",
    "UCV = ticker_call_to_sell_target.midpoint()\n",
    "\n",
    "ticker_put_to_sell_target = tickers_dict['P', Down_Put]\n",
    "LPV = ticker_put_to_sell_target.midpoint()\n",
    "\n",
    "print(f'current price({Entry})')\n",
    "print(f'upper_strike ({Up_Call}) at {UCV}')\n",
    "print(f'lower_strike ({Down_Put}) at {LPV}')\n",
    "\n",
    "#############################\n",
    "#SELL options\n",
    "#############################\n",
    "\n",
    "#\n",
    "#get price of the asset\n",
    "\n",
    "spot = ib.reqMktData(contract = contract, genericTickList=\"\", snapshot=False, regulatorySnapshot=False)\n",
    "stock_price = spot.last\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame([{'time':datetime.now(),'upper_Call_value': UCV, 'stock_price':stock_price, 'lower_Put_value': LPV}])\n",
    "\n",
    "df.to_pickle('price_move.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ca7cb5-caee-4ca2-aae2-d40723095267",
   "metadata": {},
   "outputs": [],
   "source": [
    "def job(valid_options, Up_Call, Down_Put ):\n",
    "    \n",
    "    tickers_dict = {}\n",
    "    \n",
    "    for option in valid_options:\n",
    "        tickers_dict[(option.right, option.strike)] = ib.reqMktData(contract =option, genericTickList=\"\", snapshot=False, regulatorySnapshot=False)\n",
    "    \n",
    "    ib.sleep(3)\n",
    "    ticker_call_to_sell_target = tickers_dict['C', Up_Call]\n",
    "    UCV = ticker_call_to_sell_target.midpoint()\n",
    "    \n",
    "    ticker_put_to_sell_target = tickers_dict['P', Down_Put]\n",
    "    LPV = ticker_put_to_sell_target.midpoint()\n",
    "    \n",
    "    print(f'current price({Entry})')\n",
    "    print(f'upper_strike price({Up_Call})')\n",
    "    print(f'upper_strike price({Down_Put})')\n",
    "\n",
    "    df = pd.read_pickle('price_move.pkl')\n",
    "    new_row = pd.DataFrame([{'time':datetime.now(),'upper_Call_value': UCV, 'stock_price':stock_price, 'lower_Put_value': LPV}])\n",
    "    \n",
    "    # Append the new row using concat\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "    \n",
    "    df.to_pickle('price_move.pkl')\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ca3c3-27f7-4ac6-a998-bb65ea8bb9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import schedule\n",
    "#import time as st_time\n",
    "\n",
    "# def job():\n",
    "#     # Replace this with the code you want to run\n",
    "#     print(\"Running script...\", datetime.datetime.now())\n",
    "\n",
    "def run_within_time_window(start_time_str, end_time_str, interval_seconds):\n",
    "    start_time = datetime.strptime(start_time_str, '%H:%M:%S').time()\n",
    "    end_time = datetime.strptime(end_time_str, '%H:%M:%S').time()\n",
    "\n",
    "    while True:\n",
    "        now = datetime.now()\n",
    "        current_time = now.time()\n",
    "\n",
    "        if start_time <= current_time <= end_time:\n",
    "            schedule.run_pending()\n",
    "        elif current_time > end_time:\n",
    "            print(\"Time window ended.\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"Waiting for time window...\")\n",
    "\n",
    "        ib.sleep(10)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start_time_str = '13:05:00'  # Start time (HH:MM:SS)\n",
    "    end_time_str = '16:00:00'    # End time (HH:MM:SS)\n",
    "    interval_seconds = 60   # Run every hour\n",
    "\n",
    "    schedule.every(interval_seconds).seconds.do(job, valid_options = valid_options, Up_Call = Up_Call,  Down_Put = Down_Put)\n",
    "\n",
    "    run_within_time_window(start_time_str, end_time_str, interval_seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a90187c-d3ed-43b8-954f-3f1290ea099d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review = pd.read_pickle('price_move.pkl')\n",
    "\n",
    "df_review['time'] =df_review['time'].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "df_review['time'] = pd.to_datetime(df_review['time'])\n",
    "df_review.index = df_review['time']\n",
    "df_review.drop('time',axis=1, inplace=True)\n",
    "df_review.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21498185-98c9-449e-b160-edd1466356f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3760ffa-4a84-4651-9c6b-bb64e397c3bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
